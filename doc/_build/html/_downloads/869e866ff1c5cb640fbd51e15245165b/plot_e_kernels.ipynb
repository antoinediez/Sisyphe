{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Tutorial 05: Kernels and averages\n\nSimulating swarming models requires expensive mean-field convolution operations of the form: \n\n\\begin{align}J^i = \\frac{1}{N}\\sum_{j=1}^N K(|X^j-X^i|) U^j,\\end{align}\nfor $1\\leq i\\leq N$, where $(X^i)_{1\\leq i \\leq N}$ are the positions of the particles, $(U^j)_{1\\leq j\\leq N}$ are given vectors and $K$ is an **observation kernel**. Typically, $K(|X^i-X^j|)$ is equal to 1 if $X^i$ and $X^j$ are at distance smaller than a fixed interaction distance and 0 otherwise. Other kernels are defined in the module :mod:`sisyphe.kernels`. Below, we show a simple application case. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear local averages\n\nFirst, some standard imports...\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time \nimport math\nimport torch\nfrom matplotlib import pyplot as plt\n\nuse_cuda = torch.cuda.is_available()\ndtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let the $N$ particles be uniformly scattered in a box of size $L$ with interaction radius  $R$.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N = 100000\nL = 1. \nR = .15\n\npos = L*torch.rand((N,2)).type(dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also assume that the particles have a bounded cone of vision around an axis (defined by a unit vector). The default behaviour is a full vision angle equal to $2\\pi$ in which case the axis is a :data:`None` object. Here we take a cone of vision with angle $\\pi/2$ around an axis which is sampled uniformly. For the :class:`sisyphe.particles.KineticParticles`, the default axis is the velocity. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "angle = math.pi/2\naxis = torch.randn(N,2).type(dtype)\naxis = axis/torch.norm(axis,dim=1).reshape((N,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us create an instance of a particle system with these parameters. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sisyphe.particles import Particles \n\nparticles = Particles(\n    pos = pos,\n    interaction_radius = R,\n    box_size = L,\n    vision_angle = angle,\n    axis = axis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>By default, the system and the operations below are defined with periodic boundary conditions.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a simple application, we can compute the number of neighbours of each particle and print the number of neighbours of the first particle. This operation is already implemented in the method :func:`number_of_neighbours() <sisyphe.particles.Particles.number_of_neighbours>`. It simply corresponds to the average: \n\n\\begin{align}N^i_\\mathrm{neigh} = \\sum_{j=1}^N K(|X^j-X^i|).\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Nneigh = particles.number_of_neighbours()\n\nNneigh0 = int(Nneigh[0].item())\n\nprint(\"The first particle sees \" + str(Nneigh0) + \" other particles.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For custom objects, the mean-field average can be computed using the method :func:`linear_local_average() <sisyphe.particles.Particles.linear_local_average>`. As an example, let us compute the center of mass of the neighbours of each particle. First we define the quantity $U$ that we want to average. Here, since we are working on a torus, there are two: the sine and the cosine of the spatial coordinates. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cos_pos = torch.cos((2*math.pi / L) * particles.pos)\nsin_pos = torch.sin((2*math.pi / L) * particles.pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we compute the two mean field averages, i.e. the standard convolution over the $N$ particles. The center of mass along each dimension is the argument of the complex number whose coordinates are the average cosine and sine. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "average_cos, average_sin = particles.linear_local_average(cos_pos, sin_pos)\ncenter_x = torch.atan2(average_sin[:,0], average_cos[:,0])\ncenter_x = (L / (2*math.pi)) * torch.remainder(center_x, 2*math.pi)\ncenter_y = torch.atan2(average_sin[:,1], average_cos[:,1])\ncenter_y = (L / (2*math.pi)) * torch.remainder(center_y, 2*math.pi)\n\ncenter_of_mass = torch.cat((center_x.reshape((N,1)), center_y.reshape((N,1))),\n                            dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the method :func:`linear_local_average() <sisyphe.particles.Particles.linear_local_average>`, the default observation kernel is a :class:`LazyTensor` of size $(N,N)$ whose $(i,j)$ component is equal to 1 when particle $j$ belongs to the cone of vision of particle $i$ and 0 otherwise. To retrieve the indexes of the particles which belong to the cone of vision of the first particle, we can use the `K-nearest-neighbours reduction <https://www.kernel-operations.io/keops/_auto_tutorials/knn/plot_knn_mnist.html#sphx-glr-auto-tutorials-knn-plot-knn-mnist-py>`_ provided by the `KeOps <https://www.kernel-operations.io/keops/index.html>`_ library. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sisyphe.kernels import lazy_interaction_kernel\n\ninteraction_kernel = lazy_interaction_kernel(\n    particles.pos, \n    particles.pos, \n    particles.R,\n    particles.L,\n    boundary_conditions = particles.bc,\n    vision_angle = particles.angle,\n    axis = particles.axis)\n\nK_ij = 1. - interaction_kernel \n\nneigh0 = K_ij.argKmin(Nneigh0, dim=1)[0]\n\nprint(\"The indexes of the neighbours of the first particles are: \")\nprint(neigh0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, a fancy display of what we have computed. We plot the full particle system in black, the first particle in orange, its neighbours in blue and the center of mass of the neighbours in red. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "xall = particles.pos[:,0].cpu().numpy()\nyall = particles.pos[:,1].cpu().numpy()\n\nx = particles.pos[neigh0,0].cpu().numpy()\ny = particles.pos[neigh0,1].cpu().numpy()\n\nx0 = particles.pos[0,0].item()\ny0 = particles.pos[0,1].item()\n\nxc = center_of_mass[0,0].item()\nyc = center_of_mass[0,1].item()\n\n\nfig, ax = plt.subplots(figsize=(6,6))\nax.scatter(xall, yall, s=.003, c='black')\nax.scatter(x, y, s=.3)\nax.scatter(x0, y0, s=24)\nax.scatter(xc, yc, s=24, c='red')\nax.axis([0, L, 0, L])\nax.set_aspect(\"equal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nonlinear averages\n\nIn some cases, we need to compute a **nonlinear average** of the form \n\n\\begin{align}J^i = \\frac{1}{N}\\sum_{j=1}^N K(|X^j-X^i|) b(U^i,V^j),\\end{align}\n\nwhere $(U^i)_{1\\leq i \\leq N}$ and $(V^j)_{1\\leq j \\leq N}$ are given vectors and $b$ is a given function. When the **binary formula** $b$ can be written as a :class:`LazyTensor`, this can be computed with the method :func:`nonlinear_local_average() <sisyphe.particles.Particles.nonlinear_local_average>`. \n\nFor instance, let us compute the local mean square distance: \n\n\\begin{align}J^i = \\frac{\\sum_{j=1}^N K(|X^j-X^i|) |X^j-X^i|^2}{\\sum_{j=1}^N K(|X^j-X^i|)}.\\end{align}\n\nIn this case, we can use the function :func:`sisyphe.kernels.lazy_xy_matrix` to define a custom binary formula. Given two vectors $X=(X^i)_{1\\leq i\\leq M}$ and $Y = (Y^j)_{1\\leq j\\leq N}$, respectively of sizes $(M,d)$ and $(N,d)$, the $XY$ matrix is a $(M,N,d)$ LazyTensor whose $(i,j,:)$ component is the vector $Y^j-X^i$. \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sisyphe.kernels import lazy_xy_matrix \n\ndef b(x,y): \n    K_ij = lazy_xy_matrix(x,y,particles.L)\n    return (K_ij ** 2).sum(-1)\n\nx = particles.pos\ny = particles.pos\nmean_square_dist = N/Nneigh.reshape((N,1)) * particles.nonlinear_local_average(b,x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the particles are uniformly scattered in the box, the theoretical value is \n\n\\begin{align}MSD_0 = \\frac{\\int_0^R \\int_0^{\\pi/2} r^3 \\mathrm{d}r\\mathrm{d}\\theta}{\\int_0^R \\int_0^{\\pi/2} r \\mathrm{d}r\\mathrm{d}\\theta} = \\frac{R^2}{2}\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Theoretical value: \" + str(R**2/2))\nprint(\"Experimental value: \" + str(mean_square_dist[0].item()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}